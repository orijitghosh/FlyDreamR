% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/HMMbehavrFast.R
\name{HMMbehavrFast}
\alias{HMMbehavrFast}
\title{Parallel Hidden Markov Model for Sleep State Inference}
\usage{
HMMbehavrFast(behavtbl, it = 100, n_cores = 4, ldcyc = NULL)
}
\arguments{
\item{behavtbl}{A \code{behavr} table containing behavioral data for multiple
individuals. See \code{\link{HMMbehavr}} for required columns.}

\item{it}{Integer (>= 100) specifying the number of HMM fitting iterations
per individual per day. Default: 100. See \code{\link{HMMbehavr}} for details.}

\item{n_cores}{Integer specifying the number of CPU cores to use for parallel
processing. Default: 4.

\strong{Recommendations:}
\itemize{
\item Leave 1-2 cores free for system operations
\item On HPC: request cores matching this parameter
\item Typical desktop: use 2-4 cores
\item Check available cores: \code{parallel::detectCores()}
}}

\item{ldcyc}{Numeric specifying light phase duration in hours. If \code{NULL}
(default), assumes 12-hour light phase. See \code{\link{HMMbehavr}} for details.}
}
\value{
A list containing two data frames with combined results from all
individuals:
\describe{
\item{\code{TimeSpentInEachState}}{Time spent in each state for all individuals}
\item{\code{VITERBIDecodedProfile}}{HMM-inferred state profiles for all individuals}
}

See \code{\link{HMMbehavr}} for detailed description of output structure.
}
\description{
Parallelized wrapper for \code{\link{HMMbehavr}} that processes multiple
individuals simultaneously using multiple CPU cores. This function provides
significant speed improvements for large datasets while maintaining identical
output to the serial version.

Each individual's data is processed independently in parallel, making this
approach ideal for experiments with many animals. The function automatically
handles cluster setup and cleanup.
}
\details{
\subsection{Parallelization Strategy}{

The function:
\enumerate{
\item Splits data by individual ID
\item Creates a parallel cluster with \code{n_cores} workers
\item Distributes individuals across workers
\item Each worker runs \code{\link{HMMbehavr}} independently
\item Combines results after all workers complete
\item Automatically cleans up cluster
}
}

\subsection{Performance Considerations}{
\itemize{
\item \strong{Speedup}: Near-linear with number of cores (e.g., 4x faster with 4 cores)
\item \strong{Memory}: Each worker needs enough RAM for one individual's data
\item \strong{Overhead}: Setup time ~1-2 seconds; only beneficial for >5-10 individuals
\item \strong{Progress}: No progress bar (runs silently in parallel)
}
}

\subsection{Timing Comparison}{

For 32 individuals, 3 days each, it=100:
\itemize{
\item Serial (\code{HMMbehavr}): ~160 seconds
\item 4 cores (\code{HMMbehavrFast}): ~45 seconds
\item 8 cores: ~25 seconds
}
}

\subsection{Error Handling}{

If any individual fails to process, that individual returns \code{NULL} and
is excluded from the final results. Other individuals continue processing normally.
}
}
\examples{
\dontrun{
# Basic parallel processing with 4 cores
hmm_results <- HMMbehavrFast(
  behavtbl = processed_data,
  n_cores = 4
)

# Use more cores for large dataset
hmm_results <- HMMbehavrFast(
  behavtbl = processed_data,
  it = 200,
  n_cores = 8,
  ldcyc = 12
)

# Check available cores first
available_cores <- parallel::detectCores()
use_cores <- max(1, available_cores - 2)  # Leave 2 for system

hmm_results <- HMMbehavrFast(
  behavtbl = processed_data,
  n_cores = use_cores
)

# Results structure identical to HMMbehavr
time_in_states <- hmm_results$TimeSpentInEachState
state_profile <- hmm_results$VITERBIDecodedProfile
}

}
\seealso{
\code{\link{HMMbehavr}} for serial implementation and detailed HMM description
\code{\link{HMMDataPrep}} for preparing input data
\code{\link[parallel]{makeCluster}} for details on parallel backends
}
